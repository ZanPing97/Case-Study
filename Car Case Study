# import the relevant libraries for the data processing and machine learning
# you will need to use pandas, matplotlib, seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# Load the dataset for car price csv
cars = pd.read_csv("Car_price.csv") 
cars
# Explore the first 5 rows of the dataset using the head function
cars.head(5)
# View data types and for missing data using info function
cars.info()
# v = cars.isnull().sum()
#print(v)
# v.value_counts().sort_values()
# View the statistics for the dataset with describe function
cars.describe()
# using a unique function to find out the unique values of car names
cars.CarName.unique()
# Data exploration
# Build the Correlation matrix using corr function and produce it into a heatmap
corr = cars.corr(numeric_only=True) # calculate the correlation
plt.figure(figsize=(15, 10))
sns.heatmap(corr, annot=True, cmap='coolwarm')  # create a heatmap
plt.title('Correlation Matrix')
plt.show()
# Perform a Pairplot for cars datasets
sns.pairplot(cars)
plt.show()
# Data cleaning
# Drop irrelevant columns. There should be 3 columns that are not useful for machine learning
cars.drop(['car_ID', 'symboling', 'CarName'], axis=1, inplace=True)
# Scatter plot of price vs. horsepower
#cars.plot(kind ='scatter', x = 'horsepower', y = 'price', s = 150 , color = 'g')
#cars.plot(cars['horsepower'], cars['price'],s = 150 , color = 'g')
plt.scatter(cars['horsepower'], cars['price'])
plt.xlabel('Horsepower')
plt.ylabel('Price')
plt.title('Scatter Plot of Price vs. Horsepower')
plt.show()

# Import required functions. You will need to import more than 1 function
# You will need train_test_split, StandardScaler, LinearRegression, mean_squared_error, r2_score

from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score


cars = pd.read_csv("Car_price.csv") 
cars.drop(['car_ID', 'symboling', 'CarName'], axis=1, inplace=True)
cars
# Create dummy variables
sig_cat_col = ['enginetype','fueltype','aspiration','carbody','cylindernumber','drivewheel','doornumber','enginelocation','fuelsystem']
dummy_variable = pd.get_dummies(cars[sig_cat_col])
# Concat the transformed dummy columns and drop the original columns
cars = pd.concat([cars, dummy_variable],axis=1) # concat cars and the dummy_variables
print(cars)
cars.drop(sig_cat_col, axis=1, inplace=True)  # drop the original columns
print(cars)
# Perform Train-test split. Understand which is variable you want to predict to be used as Y
X = cars.drop('price', axis=1)
y = cars['price'] 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
# Perform Feature scaling using standard scaler
scaler = StandardScaler() # fit and transform X_train
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)   # tranform X_test\

#compare x_train and y_train
#reshape 
# Perform Linear regression
lr = LinearRegression()  # create the linear regression object

# fit the model
lr.fit(X_train, y_train)  

# make predictions using the X_test
lr_pred = lr.predict(X_test)

lr_mse = mean_squared_error(y_test, lr_pred)   # computing the mean_squared_error
lr_r2 = r2_score(y_test, lr_pred)  # computing the r2
#Print the results
print("R2 Score Using Standard Scaling",lr_r2)
print('Mean Squared Error  Using Standard Scaling::', lr_mse)
print('Root Mean Squared Error  Using Standard Scaling::', np.sqrt(lr_mse))
